[
  {
    "objectID": "CONTRIBUTING.html",
    "href": "CONTRIBUTING.html",
    "title": "Contributing Guidelines",
    "section": "",
    "text": "Pull requests, bug reports, and all other forms of contribution are welcomed and highly encouraged!\n\n\n\nNEVER COMMIT PRIVATE INFORMATION\nOpening an Issue\nSubmitting Pull Requests\nWriting Commit Messages\n\n\n\n\nThis is intended to be a public repository shared with other public health organizations and available to the public.\nNEVER add any: - Real case data: demographics, identifiers, test results, etc. - Private health information - Server names, keys, secrets, etc.\n\n\n\nA great way to contribute to the project is to send a detailed issue when you encounter a problem. We always appreciate a well-written, thorough bug report. Please include as much detail as possible in your issue so that the issue can easily be identified and reproduced, if applicable.\n:sparkles: Feature requests and other issues are also welcome.\n\n\n\nThis repo uses the GitHub flow as the main versioning workflow: 1. Fork the repository 2. Create a new branch for each feature, fix or improvement 3. Send a pull request from each feature branch to the main branch\nIt is very important to separate new features or improvements into separate feature branches, and to send a pull request for each branch.\n\n\n\nPlease utilize conventional commit syntax.\nThe commit message should be structured as follows:\n&lt;type&gt;[optional scope]: &lt;description&gt;\n\n[optional body]\n\n[optional footer(s)]\n&lt;type&gt; should be one of: - feat: New feature for the user, not a new feature for build script - fix: Bug fix for the user, not a fix to a build script - docs: Changes to the documentation - style: Formatting, missing semi colons, etc; no production code change - refactor: Refactoring production code, eg. renaming a variable - test: Adding missing tests, refactoring tests; no production code change - chore: Updating grunt tasks etc; no production code change\nWhen in doubt, pick whatever seems closest to your request."
  },
  {
    "objectID": "CONTRIBUTING.html#warning-never-commit-private-information",
    "href": "CONTRIBUTING.html#warning-never-commit-private-information",
    "title": "Contributing Guidelines",
    "section": "",
    "text": "This is intended to be a public repository shared with other public health organizations and available to the public.\nNEVER add any: - Real case data: demographics, identifiers, test results, etc. - Private health information - Server names, keys, secrets, etc."
  },
  {
    "objectID": "CONTRIBUTING.html#lady_beetle-opening-an-issue",
    "href": "CONTRIBUTING.html#lady_beetle-opening-an-issue",
    "title": "Contributing Guidelines",
    "section": "",
    "text": "A great way to contribute to the project is to send a detailed issue when you encounter a problem. We always appreciate a well-written, thorough bug report. Please include as much detail as possible in your issue so that the issue can easily be identified and reproduced, if applicable.\n:sparkles: Feature requests and other issues are also welcome."
  },
  {
    "objectID": "CONTRIBUTING.html#repeat-submitting-pull-requests",
    "href": "CONTRIBUTING.html#repeat-submitting-pull-requests",
    "title": "Contributing Guidelines",
    "section": "",
    "text": "This repo uses the GitHub flow as the main versioning workflow: 1. Fork the repository 2. Create a new branch for each feature, fix or improvement 3. Send a pull request from each feature branch to the main branch\nIt is very important to separate new features or improvements into separate feature branches, and to send a pull request for each branch."
  },
  {
    "objectID": "CONTRIBUTING.html#memo-writing-commit-messages",
    "href": "CONTRIBUTING.html#memo-writing-commit-messages",
    "title": "Contributing Guidelines",
    "section": "",
    "text": "Please utilize conventional commit syntax.\nThe commit message should be structured as follows:\n&lt;type&gt;[optional scope]: &lt;description&gt;\n\n[optional body]\n\n[optional footer(s)]\n&lt;type&gt; should be one of: - feat: New feature for the user, not a new feature for build script - fix: Bug fix for the user, not a fix to a build script - docs: Changes to the documentation - style: Formatting, missing semi colons, etc; no production code change - refactor: Refactoring production code, eg. renaming a variable - test: Adding missing tests, refactoring tests; no production code change - chore: Updating grunt tasks etc; no production code change\nWhen in doubt, pick whatever seems closest to your request."
  },
  {
    "objectID": "pages/example.html",
    "href": "pages/example.html",
    "title": "Example Data",
    "section": "",
    "text": "Overview\nBelow are examples of ELR submissions stored in the Washington Disease Reporting System (WDRS) replica database ELR Entire table. Data structure and formatting are real, while specific values are not.\nThis table is intended to give a visual of how data are structured at the end of the process from sequencing by external labs to HL7 messaging and finally storage of sequencing metadata in WA DOH’s COVID-19 surveillance system.\nValues are color-coded to reflect the piece of sequencing metadata they correspond to:\n\nStrain names. Also labelled isolate in GenBank or virus name in GISAID. These values may be full/complete or partial. As an example, the strain name for a sequence in GenBank is WA-CDC-LAB-12345. A lab might submit a full strain name via ELR (WA-CDC-LAB-12345), or they might submit a partial string (12345) which must be combined with lab-specific logic to create the final, full strain name.\nPango lineages\nClinical accessions. This is the value used to link a sequencing result to a specific specimen and/or lab test. This is usually submitted as the filler order number. However, a variety of factors can influence where these data might be in ELR submissions, such as which lab is submitting the sequencing results to WA DOH and whether the same or different labs conducted the diagnostic and sequencing tests.\n\n\n\nWDRS Example Data\n\n\n\nELR Example Data\n\n\nCASE_ID\nPCO\nPCO_VALUE\nSPEC_COLL_DTTM\nFILLER_ORD_NUM\nRESULT\nSPEC_PLACER_ID\nFILLER_ORD_ID\nSPEC_FILLER_ID\nPLACER_ORD_ID\n\n\n\n\nHelix\n\n\n101\nSequencing study identifier\nVSX-A0199\n2025-07-08\nVSX-A0199\nSARS-CoV-2 R.5.7 lineage\n\n\n\n\n\n\n101\n\n\n2025-07-08\nVSX-A0199\nSARS-CoV-2 R.5.7 lineage\n\nVSX-A0199\nVSX-A0199\n\n\n\n101\nAge\n5\n2025-07-08\nVSX-A0199\nSARS-CoV-2 R.5.7 lineage\n\n\n\n\n\n\n102\nSequencing study identifier\nVSX-A0712\n2025-07-04\nVSX-A0712\nSARS-CoV-2 JM.2.5 lineage\n\n\n\n\n\n\n102\n\n\n2025-07-04\nVSX-A0712\nSARS-CoV-2 JM.2.5 lineage\n\nVSX-A0712\nVSX-A0712\n\n\n\n102\nAge\n15\n2025-07-04\nVSX-A0712\nSARS-CoV-2 JM.2.5 lineage\n\n\n\n\n\n\n103\nAge\n96\n2024-05-28\nVSX-A6025\nSARS-CoV-2 X.1.12 lineage\n\n\n\n\n\n\n103\nSequencing study identifier\nVSX-A6025\n2024-05-28\nVSX-A6025\nSARS-CoV-2 X.1.12 lineage\n\n\n\n\n\n\n103\n\n\n2024-05-28\nVSX-A6025\nSARS-CoV-2 X.1.12 lineage\n\nVSX-A6025\nVSX-A6025\n\n\n\nLabCorp\n\n\n104\nSequencing study identifier|LC Identifier\nLC2679\n2025-07-11\n2211\nSARS-CoV-2 DQ.4.6.7 lineage; DQ.4.6.7\n\n2211\n\n\n\n\n105\nSequencing study identifier\nLC1227\n2026-02-02\n6890\nSARS-CoV-2 RAX.4.6.8 lineage; RAX.4.6.8\n\n6890\n\n\n\n\n106\n\n\n2024-05-08\n5016\nSARS-CoV-2 DE.6.5.4 lineage; DE.6.5.4\n\n5016\n\n\n\n\nQuest\n\n\n107\n\n\n2025-10-17\n2412\nSARS-CoV-2 O.4.3.4 lineage\nOW5143V\n2412\n2412\nOW5143V\n\n\n107\nSequencing study identifierAllowable\nWA-QDX-2412\n2025-10-17\n2412\nSARS-CoV-2 O.4.3.4 lineage\n\n\n\n\n\n\n107\nOriginal Submitter Lab SpecimenID\nOW5143V\n2025-10-17\n2412\nSARS-CoV-2 O.4.3.4 lineage\n\n\n\n\n\n\n108\n\n\n2024-02-28\n0178\nSARS-CoV-2 R.5.7 lineage\nOW2689W\n0178\n0178\nOW2689W\n\n\n108\nSequencing study identifierAllowable\nWA-QDX-0178\n2024-02-28\n0178\nSARS-CoV-2 R.5.7 lineage\n\n\n\n\n\n\n108\nOriginal Submitter Lab SpecimenID\nOW2689W\n2024-02-28\n0178\nSARS-CoV-2 R.5.7 lineage\n\n\n\n\n\n\n109\nSequencing study identifierAllowable\nWA-QDX-0367\n2024-05-01\n0367\nSARS-CoV-2 TS.2.16 lineage\n\n\n\n\n\n\n109\n\n\n2024-05-01\n0367\nSARS-CoV-2 TS.2.16 lineage\nOW2180X\n0367\n0367\nOW2180X\n\n\n109\nOriginal Submitter Lab SpecimenID\nOW2180X\n2024-05-01\n0367\nSARS-CoV-2 TS.2.16 lineage\n\n\n\n\n\n\nUW\n\n\n110\nSEQUENCING STUDY IDENTIFIER\nWA-CDC-UW8241\n2026-03-16\nT4281\nSARS-CoV-2 CV.6.16 lineage\nT4281\nT4281\nF4164\nT4281\n\n\n111\nSEQUENCING STUDY IDENTIFIER\nWA-CDC-UW0885\n2026-03-14\nM0592\nSARS-CoV-2 M.1.5.19 lineage\nM0592\nM0592\nF4164\nM0592\n\n\n112\nSEQUENCING STUDY IDENTIFIER\nWA-CDC-UW9694\n2024-08-16\nX8663\nSARS-CoV-2 UIQ.2.12 lineage\nX8663\nX8663\nF4164\nX8663\n\n\n\n\n\n\n\nRaw data set:  \n\n\n\n\n\n\n\n\nKey\n\n\n\n\n\nFull NCBI/GISAID strain name\n\n\nPartial NCBI/GISAID strain name\n\n\nLineage\n\n\nClinical accession\n\n\n\n\n\n\nAbbreviated Variable Names\n\n\nAbbreviation\nWDRS Name\n\n\n\n\nPCO\nPATIENT__CENTRIC__OBSERVATION\n\n\nPCO_VALUE\nPATIENT__CENTRIC__OBSERVATION__VALUE\n\n\nSPEC_COLL_DTTM\nSPECIMEN__COLLECTION__DTTM\n\n\nFILLER_ORD_NUM\nFILLER__ORDER__NUM\n\n\nRESULT\nTEST__RESULT\n\n\nSPEC_FILLER_ID\nSPECIMEN_FILLER_ID_SPM0202\n\n\nFILLER_ORD_ID\nFILLER_ORDER_ID_OBR03\n\n\nPLACER_ORD_ID\nPLACER_ORDER_ID_OBR02\n\n\nSPEC_PLACER_ID\nSPECIMEN_PLACER_ID_SPM0201\n\n\n\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThe HL7 content below is under construction. Links and data display may be broken and/or change.\n\n\n\n\nHL7 Example Data\n\n#| '!! shinylive warning !!': |\n#|   shinylive does not work in self-contained HTML documents.\n#|   Please set `embed-resources: false` in your metadata.\n#| standalone: true\n#| viewerHeight: 650\n\nlibrary(shiny)\n\n# import custom hl7 funs\nlibrary(dplyr)\nlibrary(stringr)\n\nhl7_element_names &lt;- function(v) {\n  #' Get dataframe with element names for HL7 fields\n  #' \n  #' Currently maps element names (at the field-level) for HL7 versions 2.3.1 and 2.5.1. Reads data from public github page.\n  #' \n  #' Parameters:\n  #'  v: version number. Should be \"2.3.1\" or \"2.5.1\". Defaults to 2.5.1\n  #' Returns: df containing Segment (char), Name (char), and Field (int) fields\n\n  if (v == \"2.3.1\") {\n    hl7_mapping = read.csv(url(\"https://raw.githubusercontent.com/NW-PaGe/covid_seq_elr/refs/heads/main/data/hl7_231_mapping.csv\"),\n                           na.strings = c(\"\", \"NA\"))\n  } else {\n    if (v != \"2.5.1\") warning(\"Version != 2.3.1 or 2.5.1; parsing with 2.5.1 schema\")\n    hl7_mapping = read.csv(url(\"https://raw.githubusercontent.com/NW-PaGe/covid_seq_elr/refs/heads/main/data/hl7_251_mapping.csv\"),\n                           na.strings = c(\"\", \"NA\"))\n  } \n  # Create additional rows for messages w/empty component/subcomponent even if they can exist:\n  hl7_empty_subcomponent = hl7_mapping %&gt;% mutate(Subcomponent = NA, Subcomponent_Name = NA)\n  hl7_empty_component = hl7_empty_subcomponent %&gt;% mutate(Component = NA, Component_Name = NA)\n  # Combine all variations of component/subcomponent emptiness and get unique rows\n  hl7_mapping_final = rbind(hl7_mapping, \n                            hl7_empty_subcomponent, \n                            hl7_empty_component) %&gt;%\n    distinct() %&gt;% \n    mutate(\n      Name = case_when(\n        is.na(Component_Name) & is.na(Subcomponent_Name) ~ Field_Name,\n        is.na(Subcomponent_Name) ~ paste(Field_Name, Component_Name, sep = \": \"),\n        T ~ paste(Field_Name, Component_Name, Subcomponent_Name, sep = \": \")\n      )\n    )\n  \n  return(hl7_mapping_final)\n}\n\n# Convert HL7 Strings into a table\nparse_hl7 &lt;- function(hl7, remove_pii=TRUE) {\n  #' Create a dataframe from raw HL7 message\n  #' \n  #' Segments should be separated by a carraige return and new line characters (\\r\\n)\n  #' \n  #' Parameters:\n  #'  hl7: string form of the HL7 message\n  #'  remove_pii: default TRUE; if TRUE, remove potential PII from PID segment and other fields, including some provider information\n  #' \n  #' Returns: df with a row for every distinct segment/field/repetition/component/subcomponent in the message. Output schema:\n  #'  - Order (int): int sequence from 1-N for N total rows. The order of the elements in the message\n  #'  - Value (char): the character value of the message element\n  #'  - Position (char): Positional description of the element in the following format: Segment[Instance]-Field[Repetition].Component.Subcomponent\n  #'    Instance, repetition, Component, and Subcomponent are excluded if they do not exist for that element.\n  #'    (Instance is only include if &gt;= 2 instances exist in the message for a given Segment)\n  #'  - Name (char): The data element name for a given Segment's Field. Componenets and Subcomponents are not named in further detail.\n  #'  - Segment (char): 3-character str containig Segment name\n  #'  - Instance (int): the order the segment is in, relative to all other same-named segments. Value is NA is only one segment instance exists.\n  #'  - Field (int): the order the field is in, relative to the other Fields in the same segment instance\n  #'  - Repetition (int): the order the repetition is in, relative to the other Repetitions in the same Field instance\n  #'  - Component(int): the order the Componenet is in, relative to the other Components in the same Field, or Repetition if it exists, instance\n  #'  - Subcomponent (int): the order the Subcomponent is in, relative to the other Subcomponents in the same Component instance.\n\n  hl7 = gsub('\\\\\\\\&amp', '\\\\\\\\&', hl7) # replace amp replacement with just amp\n  hl7 = gsub('&amp;', '&', hl7, fixed=TRUE) # replace amp replacement with just amp\n  hl7_fields_seps = gsub(\"^.{0,}MSH\\\\|\", '', hl7) # get the MSH-2 elements which contain the componenet, rep, escape, and subcomponent chars\n  hl7_fields_seps = substr(hl7_fields_seps, 1, 4) # keep only the separator chars\n  hl7_seps_list = list(\"component\" = substr(hl7_fields_seps, 1, 1), # set component separator char\n                       \"repetition\" = substr(hl7_fields_seps, 2, 2), # set repetition separator char\n                       \"escape\" = substr(hl7_fields_seps, 3, 3), # set escape char\n                       \"subcomponent\" = substr(hl7_fields_seps, 4, 4)) # set subcomponent char\n  hl7 = gsub(paste0(\"MSH|\", hl7_fields_seps), \"MSH|__**separators**__\", hl7, fixed=TRUE) # temporarily remove MSH-2 so special chars don't get targeted during transformations\n  # Get field names\n  hl7_version = gsub(\"^.{0,}MSH(\\\\|[^|]{0,}){10}\\\\|([0-9\\\\.]{3,})\", '\\\\2', hl7) # remove version prefix\n  hl7_version = gsub(\"^([0-9\\\\.]+).+$\", \"\\\\1\", hl7_version) # remove version suffix\n  element_names_df = hl7_element_names(hl7_version) # get names for fields\n  \n  df = data.frame() # set empty df to capture message data\n  \n  segments = unlist(strsplit(hl7, \"\\r\\n\", fixed=TRUE)) # split segments by carriage returns\\new line combos\n  # Track occurrences of each segment type (used in naming of positions later)\n  segment_counts &lt;- table(sapply(segments, function(segment) unlist(strsplit(segment, \"|\", fixed=TRUE))[1])) # Get counts of segment occurance\n  segment_instance_tracker &lt;- list() # set empty list to track processing of segments\n  \n  for (segment in segments) {\n    parts = unlist(strsplit(segment, \"|\", fixed=TRUE))\n    segment_name = parts[1]\n    if (segment_name != \"MSH\") {\n      if (length(parts) == 1) { # if there are no fields outside of the field name, set to null\n        parts = NULL\n      } else {\n        parts = parts[2:length(parts)]  # otherwise, cutoff field name\n      }\n    }\n    \n    # Track the instance number for the segment\n    if (!segment_name %in% names(segment_instance_tracker)) { # if segment name hasn't been processed prev, set count to 1\n      segment_instance_tracker[[segment_name]] &lt;- 1\n    } else { # otherwise, add 1 to processing count\n      segment_instance_tracker[[segment_name]] &lt;- segment_instance_tracker[[segment_name]] + 1\n    }\n    segment_instance &lt;- segment_instance_tracker[[segment_name]] # After setting or adding to the processing count, get the count total\n    \n    for (field_i in seq_along(parts)) { # break each field up into it's repetitions\n      repetitions = unlist(strsplit(parts[field_i], hl7_seps_list$repetition, fixed=TRUE))\n      if (length(repetitions) == 0) repetitions = \"\"\n      \n      for (rep_i in seq_along(repetitions)) { # break each repetition up into it's components\n        components = unlist(strsplit(repetitions[rep_i], hl7_seps_list$component, fixed=TRUE))\n        if (length(components) == 0) components = \"\"\n        \n        for (comp_i in seq_along(components)) { # break each component up into it's subcomponents\n          subcomponents = unlist(strsplit(components[comp_i], hl7_seps_list$subcomponent, fixed=TRUE))\n          if (length(subcomponents) == 0) subcomponents = \"\"\n          \n          for (sub_i in seq_along(subcomponents)) {\n            include_segment_instance = segment_counts[segment_name] &gt; 1 # include an Instance Value if there are more than 1 segment instances in message\n            new_df = data.frame(\"Segment\" = segment_name, # set segment name\n                                \"Instance\" = ifelse(include_segment_instance, segment_instance, NA), # set instance (if applicable)\n                                \"Field\" = field_i, # Set field number\n                                \"Component\" = ifelse(length(components) &gt; 1, comp_i, NA), # set component number (if applicable)\n                                \"Subcomponent\" = ifelse(length(subcomponents) &gt; 1, sub_i, NA), # set subcomponent number (if applicable)\n                                \"Repetition\" = ifelse(length(repetitions) &gt; 1, rep_i, NA), # set repetition number (if applicable)\n                                \"Position\" = paste0( # Create name for position in this format: segment[instance#]-field#[rep#].comp#.sub#\n                                  segment_name, # include segment\n                                  ifelse(include_segment_instance, paste0(\"[\", segment_instance, \"]\"), \"\"), # include instance (if the segment occurs more than once)\n                                  \"-\", field_i, # include the field\n                                  ifelse(length(repetitions) &gt; 1, paste0(\"[\", rep_i, \"]\"), \"\"), # include the repetition (if field repeats more than once)\n                                  ifelse(length(components) &gt; 1, paste0(\".\", comp_i), \"\"), # include the component (if the field has more than one component)\n                                  ifelse(length(subcomponents) &gt; 1, paste0(\".\", sub_i), \"\") # include the subcomponent (if the component has more than one subcomponent)\n                                ),\n                                \"Value\" = subcomponents[sub_i] # set the raw value\n            )\n            df = rbind(df, new_df) # append the new df to the growing final df\n          }\n        }\n      }\n    }    \n  }\n  df$Order = seq_along(df$Segment) # Create Index to track absolute position within message\n  # Join the field + component (if present) + subcomponent (if present) names as a new field (\"Name\"):\n  df = left_join(df, element_names_df, by=c(\"Segment\", \"Field\", \"Component\", \"Subcomponent\")) \n  # join missing names if needed:\n  missing_name = filter(df, is.na(Name))\n  if (nrow(missing_name) &gt; 0) {\n    missing_name = missing_name %&gt;%\n      left_join(element_names_df, by=c(\"Segment\", \"Field\", \"Component\"), suffix = c(\"\", \"_drop\")) %&gt;% # Join names w/o subcomponent\n      mutate(Name_no_sub = if_else(!is.na(Name_drop) & !is.na(Component_Name_drop), # create name by combining Field name and Component name\n                                   paste(Name_drop, Component_Name_drop, sep = \": \"),\n                                   NA)) %&gt;%\n      select(-ends_with(\"_drop\")) %&gt;% \n      left_join(element_names_df, by=c(\"Segment\", \"Field\"), suffix = c(\"\", \"_drop\"), relationship = \"many-to-many\") %&gt;% \n      rename(Name_no_comp = Field_Name_drop) %&gt;% \n      select(-ends_with(\"_drop\")) %&gt;%\n      mutate(Name = case_when(!is.na(Name_no_sub) ~ Name_no_sub, !is.na(Name_no_comp) ~ Name_no_comp)) %&gt;% \n      select(-Name_no_sub, -Name_no_comp) %&gt;% \n      distinct()\n    # join rows with missing names (which should now be filled) with the rows that originally were not missing\n    df = df %&gt;% filter(!is.na(Name)) %&gt;% rbind(missing_name) %&gt;% arrange(Order)\n  }\n  # remove pii if indicated\n  if (remove_pii) { # default is TRUE; if TRUE, remove potential PII\n    date_name = grepl(\"date|time\", df$Name, ignore.case=T) # find fields with date or time in name\n    id_fields= c(\"ordering facility name\", \n                 \"address\", \n                 \"Message Control ID\", \n                 \"Security\", \n                 \"Ordering Provider\", \n                 \"Performing Organization Medical Director\",\n                 \"Producer's ID\", \n                 \"Relevant Clinical Info\", \n                 \"ssn\", \n                 \"driver's license\", \n                 \"Mother's\",\n                 \"Patient Identifier\", \n                 \"patient\", \n                 \"phone\", \n                 \"county\", \n                 \"race\",\n                 \"sex\", \n                 \"marital\", \n                 \"religion\", \n                 \"ethnic\")\n    id_name = grepl(paste0(id_fields, collapse=\"|\"), df$Name, ignore.case=TRUE) # find fields that likely contain identifiers\n    id_name = id_name & df$Name != \"Software Product Name\" # remove Software name from masked ids\n    id_name = id_name | df$Segment == \"PID\" # include any PID segment fields\n    # mask dates\n    df[date_name, \"Value\"] = gsub(\"(^|\\\\D)(\\\\d{8})($|\\\\D)\", # find YYYYMMDD strings \n                                      \"\\\\1YYYYMMDD\\\\3\", \n                                      df[date_name, \"Value\"])\n    df[date_name, \"Value\"] = gsub(\"(^|\\\\D)(\\\\d{12})($|\\\\D)\", # find YYYYMMDDHHMM strings\n                                      \"\\\\1YYYYMMDDHHMM\\\\3\", \n                                      df[date_name, \"Value\"])\n    df[date_name, \"Value\"] = gsub(\"(^|\\\\D)(\\\\d{14})($|\\\\D)\", # find YYYYMMDDHHMMSS strings\n                                      \"\\\\1YYYYMMDDHHMMSS\\\\3\", \n                                      df[date_name, \"Value\"])\n    # mask identifiers\n    df[id_name, \"Value\"] &lt;- gsub(\"\\\\w|\\\\s\", \"__char__\", df[id_name, \"Value\"])\n    # replace long strings (8+) of removed characters with some length of X's (between 5 and 10 repeats) \n    while(any(grepl('(__char__){8,}', df$Value))) {\n      df$Value = sub('__char____char____char____char____char____char____char__(__char__)+', \n                         paste(rep(\"X\", round(min(10, max(5, rnorm(1, 7, 1.75))))), collapse=\"\"), df$Value)\n    }\n    df$Value = gsub(\"__char__\", \"X\", df$Value, fixed=TRUE) # replace any shorter length of removed values\n  }\n  df$Value[df$Position == \"MSH-2\"] = hl7_fields_seps # reset the separator text that was removed earlier\n  # Order cols in return df:\n  df = select(df, Order, Value, Position, Name, Segment, Instance, Field, Repetition, Component, Subcomponent)\n  \n  return(df)\n}\n\n# Convert HL7 Dataframes back into strings:\ngenerate_hl7 &lt;- function(df, field_sep=\"|\", segment_sep=\"\\r\\n\") {\n  #' Flattens a df of HL7 elements into a single string\n  #'\n  #' Param:\n  #'  - df: dataframe containing Value, Segment, Instance, Field, Repetition, Component, Subcomponent fields\n  #'        (see parse_hl7 for field descriptions)\n  #'  - field_sep: separator used between fields; default pipe (\"|\")\n  #'  - segment_sep: separator used between segments; default carraige return + new line (\"\\r\\n\")\n  #' \n  #' Returns: character element with df$Value joined with appropriate separators based on MSH-2 values\n  #'\n  hl7_fields_seps = df$Value[df$Segment == 'MSH' & df$Field == 2] # keep only the separator chars\n  hl7_seps_list = list(\"component\" = substr(hl7_fields_seps, 1, 1), # set component separator char\n                       \"repetition\" = substr(hl7_fields_seps, 2, 2), # set repetition separator char\n                       \"escape\" = substr(hl7_fields_seps, 3, 3), # set escape char\n                       \"subcomponent\" = substr(hl7_fields_seps, 4, 4)) # set subcomponent char\n  \n  segments = df %&gt;% \n    select(Value, Segment, Instance, Field, Repetition, Component, Subcomponent) %&gt;% # only keep necessary fields\n    group_by(Segment, Instance, Field, Repetition, Component) %&gt;% # grouping excludes Value and Subcomponent \n    mutate(\n      Value = paste(Value, collapse=hl7_seps_list$subcomponent), # Collapse values by Subcomponent separator\n      Subcomponent = NULL # Drop Subcomponent so we can dedup below\n    ) %&gt;% \n    distinct() %&gt;% # Remove duplicate rows which held subcomponent parts\n    group_by(Segment, Instance, Field, Repetition) %&gt;%  # Grouping excludes Component\n    mutate(\n      Value = paste(Value, collapse=hl7_seps_list$component), # Collapse values by Component separator\n      Component = NULL # Drop Component so we can dedup below\n    ) %&gt;% \n    distinct() %&gt;% # Remove duplicate rows which held Component parts\n    group_by(Segment, Instance, Field) %&gt;% # Grouping excludes repetition\n    mutate(\n      Value = paste(Value, collapse=hl7_seps_list$repetition), # Collapse values by Repetition separator\n      Repetition = NULL # Drop Repetition so we can dedup below\n    ) %&gt;% \n    distinct() %&gt;% # Remove duplicate rows which held Repetitions\n    group_by(Segment, Instance) %&gt;% # Grouping excludes Field\n    mutate(\n      Value = paste(Segment, paste(Value, collapse=field_sep), sep=field_sep), # Collapse values by Field separator; add the Separator str in front\n      Field = NULL # Drop Field so we can dedup below\n    ) %&gt;% \n    distinct() # Remove duplicate rows which held Fields\n  # We end with a df containing entire segment strings in the Value field\n  \n  message = paste(segments$Value, collapse=segment_sep) # flatten to one string\n  message = gsub(paste0(\"^MSH.{\", nchar(field_sep), \"}MSH\"), \"MSH\", message) # remove extra \"MSH\"\n  \n  return(message)\n}\n\n\n# read in data from public github\nviz_df &lt;- read.csv(url(\"https://raw.githubusercontent.com/NW-PaGe/covid_seq_elr/refs/heads/main/data/example_hl7_viz.csv\"))\n\n# import ui code\nui &lt;- fluidPage(\n  # Custom CSS tags to adjust DT button colors\n  tags$style(HTML(\"\n    /* Change the background color and text color of the dt buttons */\n    .dt-buttons .dt-button.buttons-collection {\n      background-color: #78c2ad !important;  /* Mint color for the button */\n      color: white  !important;  /* White text */\n      border: none  !important;  /* No border */\n    }\n    \n    /* On hover, change the background color */\n    .dt-buttons .dt-button.buttons-collection:hover {\n      background-color: #66a593 !important;  /* Darker mint when hovered */\n      color: white  !important;  /* White text */\n      border: none  !important;  /* No border */\n    }\n  \")),\n  titlePanel(\"HL7 Viewer\"),\n  fluidRow(\n    column(\n      width=6,\n      radioButtons(\n        inputId = \"display_format\",\n        label = \"View as:\",\n        choices = c(\"Table\"=\"Table\", \"String\"=\"String\"),\n        selected = \"Table\",\n        inline = TRUE  # Display radio buttons horizontally\n      )\n    ),\n    column(\n      width=6,\n      selectInput(\"selected_table\", \"Choose a Sumbitter/Case:\", \n                  choices = viz_df$Name, selected = viz_df$Name[1])\n    )\n  ),\n  tags$hr(style = \"border-top: 2px solid #000000; margin: 5px 0;\"),  # Adjust margin size before/after hr\n  DT::DTOutput(\"hl7_table\"),\n  htmlOutput(\"hl7_string\")\n)\n\n\n# import server code\nlibrary(DT)\n\nserver &lt;- function(input, output, session) {\n  selection &lt;- reactive({\n    viz_df$Name == input$selected_table\n  })\n  output$hl7_string &lt;- renderText({\n    if (input$display_format == \"String\") {\n      HTML(viz_df$String[selection()])\n    } else {\n      \"\"\n    }\n  })\n  output$hl7_table &lt;- DT::renderDT({\n    if (input$display_format == \"Table\") {\n      example_tbl &lt;- parse_hl7(\n        gsub('&lt;br&gt;', '\\r\\n', viz_df$String[selection()], fixed=T),\n        remove_pii = F\n        )\n      example_tbl$Segment &lt;- dplyr::if_else(\n        is.na(example_tbl$Instance), \n        example_tbl$Segment, \n        paste0(example_tbl$Segment, '[', example_tbl$Instance, ']') \n      )\n      example_tbl &lt;- select(example_tbl, Order, Segment, Position, Name, Value)\n      example_tbl$Segment &lt;- as.factor(example_tbl$Segment)\n      # Create searchCols list dynamically\n      searchCols_val &lt;- vector(\"list\", ncol(example_tbl)) # add one because row names are included at front\n      #searchCols_val[[which(names(example_tbl) == 'Value')]] &lt;- list(search = 'strain|accession|lineage')\n      \n      DT::datatable(\n        example_tbl,\n        rownames = FALSE, # turn off row names\n        extensions = c(\n          \"RowGroup\", # allows for grouping of rows by col\n          \"FixedHeader\", # allows for fixing headers during vertical scroll\n          \"Buttons\" # allows for built-in copy/csv/print/pdf/colvis buttons\n        ),  \n        escape = FALSE, # Allow tool tips labels in html\n        filter = \"top\", # Add filters to top of table\n        selection = list(mode=\"single\", target=\"row\"), # make \n        options = list(\n          search = list(regex = TRUE, smart = FALSE), # Allow for regex searches\n          searchCols = searchCols_val, # set regex for \"Value\" field\n          paging = FALSE,  # Disable pagination (show all rows)\n          fixedHeader = TRUE, # fix header while scrolling\n          rowGroup = list(dataSrc = which(names(example_tbl) == \"Segment\") - 1),  # Group by the \"Segment\" column (5th column is assumed to be Segment)\n          columnDefs = list(\n            list(targets = \"_all\", searchable = TRUE),  # Enable searching for all columns\n            list(targets = which(names(example_tbl) == \"Segment\") - 1, visible = FALSE)  # Hide \"Segment\" column\n          ),\n          dom = \"Bfrtip\",  # Include Buttons in the table UI, for some reason Buttons is not working if only includes in `extensions`\n          buttons = list(\n            list(\n              extend = 'collection',\n              text = \"View Sequencing Only\",\n              action = DT::JS(\n              \"function (e, dt, node, config) {\",\n              #    Define the regex pattern for filtering\n              \"   var pattern = /strain|accession|lineage/i;\",\n              #    Clear any existing column filter for the column of interest\n              \"   dt.column(4).search('');\",\n              #    Apply the regex filter to the Value column\n              \"   dt.column(4).search(pattern.source, true, false).draw();\",\n              \"}\"\n              )\n            ),\n            list(\n              extend = 'collection',\n              text = 'View ALL',\n              action = DT::JS(\n              \"function (e, dt, node, config) {\",\n              # Clear any filters applied to the Value column\n              \"   dt.column(4).search('').draw();\",\n              \"}\"\n              )\n            )\n          ),\n          initComplete = DT::JS(\n            \"function(settings, json) {\",\n            # Automatically apply the sequencing only filter\n            \"   var table = this.api();\",\n            \"   var pattern = /strain|accession|lineage/i;\",\n            \"   table.column(4).search(pattern.source, true, false).draw();\",\n            #  Change header color\n            \"   $(this.api().table().header()).css({'background-color': '#C3B1E1'});\",\n            \"}\"\n          )\n        )\n      )\n    } else {\n      NULL\n    }\n  })\n}\n\n\n# Create shiny app w/shinylive\nshinyApp(ui, server)\n\n\n\nRaw data set:"
  },
  {
    "objectID": "pages/wdrs.html",
    "href": "pages/wdrs.html",
    "title": "WDRS",
    "section": "",
    "text": "WDRS is a Maven-based electronic disease surveillance system used in Washington State. WDRS is used to receive, process, track, and analyze data for 64+ notifiable conditions in Washington State, including COVID-19.\nWDRS is Event-based, where an Event is the association of a person with a disease at a point in time. For conditions like COVID-19, one person can be associated with multiple Events for the same condition. A person can also be associated with Events for multiple conditions tracked through WDRS.\nSequencing data submitted to WA DOH come in with varying formats, including secure file transfer of comma-separated values files and ELR. Data are ingested into a workflow which outputs a roster to populate a Question Package in WDRS. This Question Package is associated at the Event-level. After ELR data are standardized and imported into the Question Package, these data will exist as a lab result (Figure 1) associated with the Event and as an instance of the Question Package (Figure 2).\nSequencing ELRs are associated with Events in a similar format that any other test results would be. A new lab is created which contains the HL7 message, standardized and reformatted to fit in the WDRS data structures. This visual shows an example of part of an ELR residing in the WDRS frontend:\nTo make data more usable for disease investigators and genetic epidemiologists, these data are moved to a Question Package in WDRS, which is linked to the Event. Question Packages are customization by WDRS developers at WA DOH and contain sets of questions related to a variety of topics from Occupation and Industry to Molecular Genetics. Sequencing metadata are stored in one Question Package. Values stored there include GISAID/NCBI virus names and accession numbers, lineages1, specimen collection dates, sequencing lab names, and clinical accessions2. This visual shows an example of sequencing metadata stored in a Question Package in the WDRS frontend:\nReporting sequencing data to WA DOH via ELR is preferable to other methods because it should enter WDRS already associated with an existing or new Event. Data sent via ELR are linked to existing Events and Persons based on a variety of identifiers (First Name, Last Name, Date of Birth, Social Security Number, etc.) and workflows (automated matching & manual review)."
  },
  {
    "objectID": "pages/wdrs.html#footnotes",
    "href": "pages/wdrs.html#footnotes",
    "title": "WDRS",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nLineages are prone to change over time. There are workflows in place to compare lineages stored in WDRS with GISAID/NCBI, and update changed lineage calls.↩︎\nClinical accessions are often a filler order number that is shared between a sequencing result and a diagnostic test result. While Test Results and Question Packages that hold sequencing metadata are both linked to the same Event, sequencing metadata is not explicitly linked to a specific specimen. This value provides a way to determine which diagnostic and sequencing results share the same specimen.↩︎"
  },
  {
    "objectID": "pages/strengths.html",
    "href": "pages/strengths.html",
    "title": "Stengths & Challenges",
    "section": "",
    "text": "ELR sequencing submissions have unique strengths and challenges due to the systems involved (and not involved) in generating the HL7 messages, as well as their integration with established surveillance systems at WA DOH. Comparing ELR with other sequencing metadata submission modes highlights some of these strengths and challenges:\n\n\n\n\n\n\n\nELR\nStrengths:\n\n\nLinkage to WDRS Event completed upstream\nWDRS Event automatically created if no Event linked\nPerson demographics (should be) included\nMostly timely reporting\nData available in WDRS outside of Question Package\n\n\nChallenges:\n\n\nDIQA cannot alter how WDRS Event linkage is done\nDifficult to onboard labs\nDifficult to get labs to change data structure for reported records\nData structure dependent on HL7 versioning and requirements from external groups\nMultiple labs submitting with data reported in multiple structures\n\n\n\n\n\n\nPHL\nStrengths:\n\n\nLinkage to WDRS Event is directly controlled by DIQA\nMostly timely reporting\nOne lab submitting; consistent data structure\n\n\nChallenges:\n\n\nLinkage to WDRS Event must be coded by DIQA\nWDRS Event must be manually created if no Event linked\nPerson demographics may not be included\nDifficult to get PHL dashboard created\nPHL reliant on a separate dashboarding team to make dashboard changes\nReliant on Selenium and prone to breaking with Chrome or page HTML updates\nData are not found in WDRS outside of Question Package\n\n\n\n\n\n\nSecure File Transfer\nStrengths:\n\n\nLinkage to WDRS Event is directly controlled by DIQA\nLess difficult for labs to change data structure for reported records\nMultiple labs submitting with data reported in a consistent structure\n\n\nChallenges:\n\n\nLinkage to WDRS Event must be coded by DIQA\nWDRS Event must be manually created if no Event linked\nPerson demographics may not be included\nDifficult to onboard labs\nReliant on Selenium and prone to breaking with Chrome or page HTML updates\nReporting is often done in batches and is delayed\nData are not found in WDRS outside of Question Package"
  },
  {
    "objectID": "pages/flow.html",
    "href": "pages/flow.html",
    "title": "Data Flow",
    "section": "",
    "text": "Data flow: Samples are sequenced by the same lab that conducted diagnostic testing or by a different lab. Labs then report results to WA DOH directly or to APHL who then send results to WA DOH. Select other “PHL” or “SFT” to view simplified flow diagrams for how data submitted via these modes enter WDRS.\n\n{\n  if(mode==\"ELR\") {\n    return mermaid`\n    %%{ init: { 'flowchart': { 'curve': 'monotoneY' }, 'theme':'base', 'themeVariables': {'primaryColor': '#eff6f3', 'primaryTextColor': '#6a6a6a', 'primaryBorderColor': '#6a6a6a', 'lineColor': '#f3969a', 'secondaryColor': '#eff6f3'}} }%%\n    flowchart TD\n    d_lab(Diagnostic Lab) --&gt; s_lab(Sequencing Lab)\n    s_lab & lab(Diagnostic & Sequencing Lab) --&gt; aphl(APHL) \n    s_lab --&gt; pre[[Pre-processor]]\n    aphl --&gt; pre\n    lab --&gt; pre\n    pre --&gt; welrs[(WELRS)] --&gt; drive[[DRIVE]] --&gt; post[[Post-processor]] --&gt; wdrs[(WDRS)]\n    post --&gt; welrs\n    wdrs --&gt; diqa{{\"Data Integration Pipeline:\n    - Data Reformatting\n    - Public Repo (NCBI/GISAID) Linkage\n    - QA\"}}\n    diqa --&gt; |\"Question \n    Package \n    Update\"| wdrs`\n  }\n  \n  if(mode==\"PHL\") {\n    return mermaid`\n    %%{ init: { 'flowchart': { 'curve': 'monotoneY' }, 'theme':'base', 'themeVariables': {'primaryColor': '#eff6f3', 'primaryTextColor': '#6a6a6a', 'primaryBorderColor': '#6a6a6a', 'lineColor': '#f3969a', 'secondaryColor': '#eff6f3'}} }%%\n    flowchart TD\n    d_lab(Diagnostic Lab) \n    d_phl[/PHL Diagnostic/] \n    d_lab & d_phl --&gt; s_phl[/PHL Sequencing/]\n    s_phl --&gt; lims[(LIMS)] --&gt; web[/Data Dashboard/]\n    web --&gt; diqa{{\"Data Integration Pipeline:\n    - &lt;i&gt;Case linkage&lt;/i&gt;\n    - Data Reformatting\n    - Public Repo (NCBI/GISAID) Linkage\n    - QA\"}}\n    diqa --&gt; |\"Question \n    Package \n    Update\"| wdrs[(WDRS)]`\n  }\n  \n  if(mode==\"SFT\") {\n    return mermaid`\n    %%{ init: { 'flowchart': { 'curve': 'monotoneY' }, 'theme':'base', 'themeVariables': {'primaryColor': '#eff6f3', 'primaryTextColor': '#6a6a6a', 'primaryBorderColor': '#6a6a6a', 'lineColor': '#f3969a', 'secondaryColor': '#eff6f3'}} }%%\n    flowchart TD\n    d_lab(Diagnostic Lab) --&gt; s_lab(Sequencing Lab)\n    s_lab & lab(Diagnostic & Sequencing Lab) --&gt; sft[/SFT Host/]\n    sft --&gt; diqa{{\"Data Integration Pipeline:\n    - &lt;i&gt;Case linkage&lt;/i&gt;\n    - Data Reformatting\n    - Public Repo (NCBI/GISAID) Linkage\n    - QA\"}}\n    diqa --&gt; |\"Question \n    Package \n    Update\"| wdrs[(WDRS)]`\n  }\n}\nviewof mode = Inputs.radio([\"ELR\", \"PHL\", \"SFT\"], {value: \"ELR\", label: \"Select mode:\"})\nmermaid`\n    %%{ init: { 'flowchart': { 'curve': 'monotoneY' }, 'theme':'base', 'themeVariables': {'primaryColor': '#eff6f3', 'primaryTextColor': '#6a6a6a', 'primaryBorderColor': '#6a6a6a', 'lineColor': '#f3969a', 'secondaryColor': '#eff6f3'}} }%%\nflowchart TD\n    ext(External Data Owner) \n    doh[/Internal Data Owner/]`\nmermaid`\n%%{ init: { 'flowchart': { 'curve': 'monotoneY' }, 'theme':'base', 'themeVariables': {'primaryColor': '#eff6f3', 'primaryTextColor': '#6a6a6a', 'primaryBorderColor': '#6a6a6a', 'lineColor': '#f3969a', 'secondaryColor': '#eff6f3'}} }%%\nflowchart TD\n    proc[[\"Data processing (software)\"]]\n    script{{\"Data processing (scripts)\"}}\n    db[(Database)]`\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDescriptions:\n\n  Sequencing Result Sources: Public Health, Academic, and Private Laboratories\n  Sequencing results are transmitted to WA DOH via ELR originating from various sources:\n  \n    The transmitting lab may be the lab that conducted diagnostic testing (e.g.: PCR) and sequencing (Diagnostic & Sequencing Lab).\n    The transmitting lab may also have only done sequencing on a sample (Sequencing Lab), while the diagnostic testing was performed by another lab before being sent for sequencing (Diagnostic Lab).\n    The transmitting lab may be APHL, who receive sequencing results from a lab (sometimes as a linelist) and then forward results to WA DOH in HL7 formatting.\n  \n\n\n\nWELRS: Washington Electronic Lab Reporting System\nWELRS is the database for all electronically-received lab reports, for all conditions. Incoming ELRs are processed, certain standardized values (such as \"Health Condtion\") are assigned, and the messages are converted from HL7 to XML formatting.\n\n\n\n\nDRIVE: Disease Reporting and Interoperability Verification Engine\nDRIVE is a Rhapsody-based system that performs the middleware processing of ELRs between WELRS and WDRS. DRIVE reformats data and standardizes values for the widely varying information received from different reporting laboratories, and sends ELRs on to WDRS for workflow processing and end-user evaluation.\n\n\n\n\nWDRS: Washington Disease Reporting System\n\nWDRS is a Maven-based electronic disease surveillance system used in Washington State. WDRS is used to receive, process, track, and analyze data for 64+ notifiable conditions in Washington State, including COVID-19.\nWDRS is Event-based, where an Event is the association of a person with a disease at a point in time. For conditions like COVID-19, one person can be associated with multiple Events for the same condtion. A person can also be associated with Events for multiple conditions tracked through WDRS.\nSee the WDRS Sequencing Data page for more details about Question Package updates and storage of SARS-CoV-2 sequencing data in WDRS.\n\n\n\n\n\nLegend:"
  },
  {
    "objectID": "pages/drive.html",
    "href": "pages/drive.html",
    "title": "DRIVE",
    "section": "",
    "text": "Overview\n\nDRIVE (Disease Reporting and Interoperability Verification Engine) is a Rhapsody-based system that performs the middleware processing of ELRs between WELRS and WDRS. DRIVE reformats data, standardizes values for the widely varying information received from different reporting laboratories, and sends ELRs on to WDRS for workflow processing and end-user evaluation.\n\n\nThe DRIVE team also manages the MPI person-matching process which utilizes vendors to create matching algorithms and person databases. This occurs after WELRS processing and before DRIVE.\n\n\nDRIVE was developed by the DOH Tech Ops team. Workflows for processing ELR messages and importing them into WDRS are managed by the DOH WDRS team. These workflows include the management of key output pairs (KOPs) which are used for standardizing values in WDRS. The WDRS team works with the ELR team, as well, on DRIVE change requests and testing.\n\n\n\nValue Standardization and KOPs\n\nDuring value standardization, DRIVE fills standardized values in fields prefixed with “WDRS_” using KOPs to determine these values. In the case of sequencing, where data are often free-text and often changing (e.g., submission of new lineages), WDRS staff must semi-manually create new KOPs for the newly-encountered, non-standardized values.\n\n\nAs WELRs reformats HL7 messages into MIFs (XML formatting), fields which may be standardized during processing by DRIVE are filled with the value “TBD_BY_DRIVE+”. SQL tables exist which contain MIFs after WELRs processing (DRIVE.SavedMIF), as well as MIFs after DRIVE processing (DRIVE.OutputMIF). Comparing WELRs and DRIVE MIFs may be useful when troubleshooting DRIVE errors."
  },
  {
    "objectID": "pages/guidance.html",
    "href": "pages/guidance.html",
    "title": "Federal Guidance",
    "section": "",
    "text": "APHL: SARS-CoV-2 Reporting Guidelines\nCDC: National standards for ELR message formatting:"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Overview",
    "section": "",
    "text": "This website gives an overview of how COVID-19 sequencing metadata are transmitted to the Washington State Department of Health (WA DOH) via Electronic Lab Reporting (ELR) and stored in one of Washington’s disease surveillance systems.\n\nOverview gives an overview of ELR data submitted by labs to WA DOH\nStrengths & Challenges evaluates the different reporting methods used at WA DOH for sequencing metadata\nData Flow describes a high-level overview of how data travel from sequencing labs to surveillance system end-users\nWDRS explains where sequencing metadata live inside the Washington Disease Reporting System\nDRIVE details DRIVE processing and how KOPs are assigned to messages/MIFs\nExample Data shows the data structure of sequencing metadata submitted to WA DOH via ELR\nFederal Guidance lists recommendations from national public health organizations around sequencing ELR’s\n\n\n\nELR onboarding dates:\n\nLabCorp: September 2021\nQuest: September 2021\nHelix: October 2021\nAegis: February 2022 (submissions ended April 2023)\nUW: January 2023\n\n\n\n\n\n\n\n\nCOVID Sequencing ELRs by Lab\n\n\n\n\n\n\nCOVID Sequencing ELRs by Lab"
  }
]